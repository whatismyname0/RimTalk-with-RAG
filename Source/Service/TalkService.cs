using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using RimTalk.Data;
using RimTalk.Source.Data;
using RimTalk.UI;
using RimTalk.Util;
using RimWorld;
using Verse;
using Cache = RimTalk.Data.Cache;
using Logger = RimTalk.Util.Logger;

namespace RimTalk.Service;

/// <summary>
/// Core service for generating and managing AI-driven conversations between pawns.
/// </summary>
public static class TalkService
{
    /// <summary>
    /// Initiates the process of generating a conversation. It performs initial checks and then
    /// starts a background task to handle the actual AI communication.
    /// </summary>
    public static bool GenerateTalk(TalkRequest talkRequest)
    {
        // Guard clauses to prevent generation when the feature is disabled or the AI service is busy.
        var settings = Settings.Get();
        if (!settings.IsEnabled || !CommonUtil.ShouldAiBeActiveOnSpeed()) return false;
        if (settings.GetActiveConfig() == null) return false;
        if (AIService.IsBusy() && talkRequest.TalkType != TalkType.User) return false;

        PawnState pawn1 = Cache.Get(talkRequest.Initiator);
        if (talkRequest.TalkType != TalkType.User && (pawn1 == null || !pawn1.CanGenerateTalk())) return false;
        
        if (!settings.AllowSimultaneousConversations && AnyPawnHasPendingResponses()) return false;

        // Ensure the recipient is valid and capable of talking.
        PawnState pawn2 = talkRequest.Recipient != null ? Cache.Get(talkRequest.Recipient) : null;
        if (pawn2 == null || talkRequest.Recipient?.Name == null || !pawn2.CanDisplayTalkStirct())
        {
            talkRequest.Recipient = null;
        }

        List<Pawn> nearbyPawns = PawnSelector.GetAllNearByPawns(talkRequest.Initiator);
        var (status, isInDanger) = talkRequest.Initiator.GetPawnStatusFull(nearbyPawns);
        
        // Avoid spamming generations if the pawn's status hasn't changed recently.
        if (talkRequest.TalkType != TalkType.User && status == pawn1.LastStatus && pawn1.RejectCount < 2)
        {
            pawn1.RejectCount++;
            return false;
        }
        
        if (talkRequest.TalkType != TalkType.User && isInDanger) talkRequest.TalkType = TalkType.Urgent;
        
        pawn1.RejectCount = 0;
        pawn1.LastStatus = status;

        // Select the most relevant pawns for the conversation context.
        List<Pawn> pawns = new List<Pawn> { talkRequest.Initiator, talkRequest.Recipient }
            .Where(p => p != null)
            .Concat(nearbyPawns.Where(p =>
            {
                var pawnState = Cache.Get(p);
                return pawnState.CanDisplayTalkStirct() && pawnState.TalkResponses.Empty();
            }))
            .Distinct()
            .Take(5)
            .ToList();

        if (pawns.Count == 1) talkRequest.IsMonologue = true;

        // Build the context and decorate the prompt with current status information.
        string context = PromptService.BuildContext(pawns);
        AIService.UpdateContext(context);
        PromptService.DecoratePrompt(talkRequest, pawns, status);

        var allInvolvedPawns = pawns.Union(nearbyPawns).Distinct().ToList();

        // Offload the AI request and processing to a background thread to avoid blocking the game's main thread.
        Task.Run(() => GenerateAndProcessTalkAsync(talkRequest, allInvolvedPawns));

        return true;
    }

    /// <summary>
    /// Handles the asynchronous AI streaming and processes the responses.
    /// </summary>
    private static async Task GenerateAndProcessTalkAsync(TalkRequest talkRequest, List<Pawn> allInvolvedPawns)
    {
        var initiator = talkRequest.Initiator;
        try
        {
            Cache.Get(initiator).IsGeneratingTalk = true;
            CommonUtil.InGameData gameData = CommonUtil.GetInGameData();

            Logger.Debug($"[TalkService] ==================== ChromaDB Query Start ====================");
            Logger.Debug($"[TalkService] Initiator: {initiator.LabelShort}");
            Logger.Debug($"[TalkService] Involved pawns count: {allInvolvedPawns.Count}");
            Logger.Debug($"[TalkService] Original prompt length: {talkRequest.Prompt.Length} chars");

            // Generate an optimized search query and result count from the prompt for ChromaDB
            Logger.Debug($"[TalkService] Step 1/4: Generating optimized search query and result count");
            AIService.ChromaSearchParams searchParams = await AIService.GenerateChromaSearchQueryAsync(talkRequest.Prompt);
            Logger.Debug($"[TalkService] Generated search query: {searchParams.content}");
            Logger.Debug($"[TalkService] Desired result count: {searchParams.num}");

            // Query relevant historical context before generating new conversation
            Logger.Debug($"[TalkService] Step 2/4: Querying ChromaDB for relevant context (max {searchParams.num} results)");
            List<ContextEntry> contextEntries = [];
            var seenTexts = new HashSet<string>();
            List<ContextEntry> newEntries = await ChromaService.QueryRelevantContextAsync(
                searchParams.content,
                allInvolvedPawns,
                maxResults: 10
            );
            foreach (ContextEntry entry in newEntries)
            {
                if (seenTexts.Add(entry.Text)) // 如果成功添加（不重复）
                {
                    contextEntries.Add(entry);
                }
            }

            Logger.Debug($"[TalkService] Query returned {contextEntries.Count} context entries (requested {searchParams.num})");
            if (contextEntries.Count > 0)
            {
                Logger.Debug($"[TalkService] Context entries:");
                for (int i = 0; i < contextEntries.Count; i++)
                {
                    Logger.Debug($"[TalkService]   [{i + 1}] Speaker: {contextEntries[i].Speaker}, " +
                        $"Relevance: {contextEntries[i].Relevance:F4}, Date: {contextEntries[i].Date}, " +
                        $"Type: {contextEntries[i].TalkType}");
                    Logger.Debug($"[TalkService]   {contextEntries[i].Text}");
                }
            }
            else
            {
                Logger.Debug($"[TalkService] No historical context found in ChromaDB");
            }

            // Enrich prompt with historical context if available
            Logger.Debug($"[TalkService] Step 3/4: Enriching prompt with historical context");
            if (contextEntries.Any())
            {
                var contextStr = ChromaService.FormatContextForPrompt(contextEntries);
                Logger.Debug($"[TalkService] Prepending context to prompt");
                talkRequest.Prompt = contextStr + talkRequest.Prompt;
                Logger.Debug($"[TalkService] Enriched prompt: {talkRequest.Prompt}");
            }
            else
            {
                Logger.Debug($"[TalkService] No context to enrich, using original prompt");
            }

            Logger.Debug($"[TalkService] Step 4/4: Streaming chat generation");
            Logger.Debug($"[TalkService] ==================== ChromaDB Query End ====================");

            // Create a dictionary for quick pawn lookup by name during streaming.
            // Use a defensive construction because multiple pawns can share the same LabelShort
            // which would cause ToDictionary to throw. Keep the first occurrence and skip duplicates.
            var playerDict = new Dictionary<string, Pawn>();
            foreach (var p in allInvolvedPawns)
            {
                var key = p.LabelShort;
                if (!playerDict.ContainsKey(key))
                {
                    playerDict[key] = p;
                }
                else
                {
                    Logger.Warning($"Duplicate pawn label detected when building playerDict: '{key}'. Using first occurrence.");
                }
            }

            var receivedResponses = new List<TalkResponse>();

            // Call the streaming chat service. The callback is executed as each piece of dialogue is parsed.
            await AIService.ChatStreaming(
                talkRequest,
                TalkHistory.GetMessageHistory(initiator),
                playerDict,
                (pawn, talkResponse) =>
                {
                    Logger.Debug($"Streamed {pawn.LabelShort}: {talkResponse.TalkType}: {talkResponse.Text}");

                    PawnState pawnState = Cache.Get(pawn);
                    talkResponse.Name = pawnState.Pawn.LabelShort;

                    // Link replies to the previous message in the conversation.
                    if (receivedResponses.Any())
                    {
                        talkResponse.ParentTalkId = receivedResponses.Last().Id;
                    }

                    receivedResponses.Add(talkResponse);

                    // Enqueue the received talk for the pawn to display later.
                    pawnState.TalkResponses.Add(talkResponse);
                }
            );

            // Once the stream is complete, save the full conversation to history and ChromaDB.
            Logger.Debug($"[TalkService] Streaming complete. Received {receivedResponses.Count} responses");
            AddResponsesToHistory(allInvolvedPawns, receivedResponses, talkRequest.Prompt);
            
            // Asynchronously store in ChromaDB
            Logger.Debug($"[TalkService] Storing conversation to ChromaDB asynchronously");
            ChromaService.StoreConversationAsync(
                receivedResponses,
                initiator,
                allInvolvedPawns,
                gameData.DateString
            );
        }
        catch (Exception ex)
        {
            Logger.Error($"[TalkService] Error in GenerateAndProcessTalkAsync: {ex.Message}");
            Logger.Error($"[TalkService] Stack trace: {ex.StackTrace}");
        }
        finally
        {
            Cache.Get(initiator).IsGeneratingTalk = false;
        }
    }

    /// <summary>
    /// Serializes the generated responses and adds them to the message history for all involved pawns.
    /// </summary>
    private static void AddResponsesToHistory(List<Pawn> pawns, List<TalkResponse> responses, string prompt)
    {
        if (!responses.Any()) return;

        string cleanedPrompt = prompt.Replace(Constant.Prompt, "");
        string serializedResponses = JsonUtil.SerializeToJson(responses);

        foreach (var pawn in pawns)
        {
            TalkHistory.AddMessageHistory(pawn, cleanedPrompt, serializedResponses);
        }
    }

    /// <summary>
    /// Iterates through all pawns on each game tick to display any queued talks.
    /// </summary>
    public static void DisplayTalk()
    {
        foreach (Pawn pawn in Cache.Keys)
        {
            PawnState pawnState = Cache.Get(pawn);
            if (pawnState == null || pawnState.TalkResponses.Empty()) continue;

            var talk = pawnState.TalkResponses.First();
            if (talk == null)
            {
                pawnState.TalkResponses.RemoveAt(0);
                continue;
            }

            // Skip this talk if its parent was ignored or the pawn is currently unable to speak.
            if (TalkHistory.IsTalkIgnored(talk.ParentTalkId) || !pawnState.CanDisplayTalk())
            {
                pawnState.IgnoreTalkResponse();
                continue;
            }

            if (!talk.IsReply() && !CommonUtil.HasPassed(pawnState.LastTalkTick, Settings.Get().TalkInterval))
            {
                continue;
            }

            int replyInterval = RimTalkSettings.ReplyInterval;
            if (pawn.IsInDanger())
            {
                replyInterval = 1;
                pawnState.IgnoreAllTalkResponses([TalkType.Urgent, TalkType.User]);
            }

            // Enforce a delay for replies to make conversations feel more natural.
            int parentTalkTick = TalkHistory.GetSpokenTick(talk.ParentTalkId);
            if (parentTalkTick == -1 || !CommonUtil.HasPassed(parentTalkTick, replyInterval)) continue;

            // Create the interaction log entry, which triggers the display of the talk bubble in-game.
            InteractionDef intDef = DefDatabase<InteractionDef>.GetNamed("RimTalkInteraction");
            var playLogEntryInteraction = new PlayLogEntry_RimTalkInteraction(intDef, pawn, pawn, null);

            Find.PlayLog.Add(playLogEntryInteraction);
            break; // Display only one talk per tick to prevent overwhelming the screen.
        }
    }

    /// <summary>
    /// Retrieves the text for a pawn's current talk. Called by the game's UI system.
    /// </summary>
    public static string GetTalk(Pawn pawn)
    {
        PawnState pawnState = Cache.Get(pawn);
        if (pawnState == null) return null;

        TalkResponse talkResponse = ConsumeTalk(pawnState);
        pawnState.LastTalkTick = GenTicks.TicksGame;

        return talkResponse.Text;
    }

    /// <summary>
    /// Dequeues a talk and updates its history as either spoken or ignored.
    /// </summary>
    public static TalkResponse ConsumeTalk(PawnState pawnState)
    {
        var talkResponse = pawnState.TalkResponses.First();
        pawnState.TalkResponses.Remove(talkResponse);
        TalkHistory.AddSpoken(talkResponse.Id);
        var apiLog = ApiHistory.GetApiLog(talkResponse.Id);
        if (apiLog != null)
            apiLog.SpokenTick = GenTicks.TicksGame;

        Overlay.NotifyLogUpdated();
        return talkResponse;
    }

    private static bool AnyPawnHasPendingResponses()
    {
        return Cache.GetAll().Any(pawnState => pawnState.TalkResponses.Count > 0);
    }
}